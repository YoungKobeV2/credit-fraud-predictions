---
title: "EDA-Exploratary Data Analysis"
author: "Lebintiti Kobe"
date: "`r Sys.Date()`"
output:
  bookdown::gitbook:
    
    split_by: section
    number_sections: F
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, error = F, message = F)
knitr::opts_chunk$set(tidy = T, tidy.opts = list(width.cutoff = 55, blanks = T))
knitr::opts_chunk$set(fig.width = 10, fig.height = 7, dpi = 700)

require(patchwork)
require(ggplot2)
require(ggthemes)
require(extrafont)

theme_set(
  theme_bw(base_size = 13, base_family = "Tahoma") +
    theme(
      plot.title = element_text(size = 17, hjust = 0, margin = margin(b = 5), face = 2),
      plot.subtitle = element_text(size = 13, hjust = 0, margin = margin(b = 20), face = 3, colour = "grey30"),
      axis.title.x = element_text(margin = , face = 4),
      axis.title.y = element_text(margin = margin(r = 10), face = 4),
      legend.key.height = unit(0.2, "lines"),
      legend.key.width = unit(10, "lines")
    )
)

```

## Goal of this section 

Use features selected from variable clustering to perform EDA and further trim our variables so we left with variables that affect the outcome . 

## Load data

```{r}
require(here)
require(tidyverse)

data <- read.csv(here("data/kaggle_dataset.csv")) %>% as_tibble()

data <- data %>%
  relocate(target)

glimpse(data)
```

## split the data 

Split data into test and train data , and data we going to use to test our api

```{r}
set.seed(545672)
require(tidymodels)

splits <- rsample::initial_validation_split(data,strata = target)

test_api <- validation(splits)
test <- testing(splits)
train <- training(splits)

test
train
test_api
```

Create folds for model tuning

```{r}
train_folds <- vfold_cv(train,strata = target,v = 2,repeats = 5)
train_folds
```

## Load selected features from variable clustering 

```{r}
train_features <- read.csv("train_features_clust.csv")$value
train_features
features_to_remove <- read.csv("variables_to_remove_clust.csv")$value
features_to_remove
all_selected_features <- read.csv("all_selected_features_clust.csv")$x
all_selected_features
```

```{r}
recipe <- train %>%
  select(all_of(train_features)) %>%
  recipe(target ~ .) %>%
  step_mutate(target = as.factor(target)) %>%
  step_indicate_na(all_predictors()) %>%
  step_rm(all_of(features_to_remove))

v_names <- recipe %>%
  prep() %>%
  juice() %>%
  colnames()

v_names %in% all_selected_features

EDA_data <- recipe %>%
  prep() %>%
  juice()

```

## Univariate Analysis

```{r}
EDA_data %>%
  select_if(is.numeric) %>%
  gather() %>%
  ggplot(aes(x = value)) +
  geom_histogram() +
  scale_x_continuous(breaks = NULL) +
  scale_y_continuous(breaks = NULL) +
  facet_wrap(~key, scales = "free") +
  theme_bw() +
  labs(
    title = "Distribution of predictors",
    caption = "Some need tranformations to fix skewness"
  )

```

Apply Yeo-Johnson transformations to our predictors 

```{r}
require(themis)

recipe_norm <- train %>%
  select(all_of(train_features)) %>%
  recipe(target ~ .) %>%
  step_mutate(target = as.factor(target)) %>%
  step_indicate_na(all_predictors()) %>%
  step_rm(all_of(features_to_remove)) %>%
  step_normalize(all_predictors()) %>%
  step_downsample(target, seed = 123)


recipe_yeo <- train %>%
  select(all_of(train_features)) %>%
  recipe(target ~ .) %>%
  step_mutate(target = as.factor(target)) %>%
  step_indicate_na(all_predictors()) %>%
  step_rm(all_of(features_to_remove)) %>%
  step_YeoJohnson(all_predictors()) %>%
  step_normalize(all_predictors()) %>%
  step_downsample(target, seed = 123)

yeo_data <- recipe_yeo %>%
  prep() %>%
  juice()

yeo_data %>%
  select_if(is.numeric) %>%
  gather() %>%
  ggplot(aes(x = value)) +
  geom_histogram() +
  scale_x_continuous(breaks = NULL) +
  scale_y_continuous(breaks = NULL) +
  facet_wrap(~key, scales = "free") +
  theme_bw() +
  labs(
    title = "Distribution of predictors after transformations",
    caption = "Skewness looks better"
  )
```

Lets evaluate if new recipe improves predictive power

```{r}
log_spec <- logistic_reg(mode = "classification", engine = "glm")
log_spec

wf_set <- workflow_set(
  preproc = list(recipe_norm = recipe_norm, recipe_yeo = recipe_yeo),
  models = list(log_model = log_spec),
  cross = T
)

fit_results <- workflow_map(
  object = wf_set,
  fn = "fit_resamples",
  resamples = train_folds,
  seed = 123
)

fit_results %>%
  workflowsets::collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(wflow_id, .metric, mean, std_err)

```

Recipe that include Yeo-Johnson performs better 

## EDA 

- Since we have to many variables , i decide to skip Plots for visually finding the useful / significant predictors . We are going to use random forest , stepwise selection and lasso models for our feature selection . 

### variable selection with Random Forest

```{r}
require(vip)
require(ranger)

recipe <- train %>%
  select(all_of(train_features)) %>%
  recipe(target ~ .) %>%
  step_mutate(target = as.factor(target)) %>%
  step_indicate_na(all_predictors()) %>%
  step_rm(all_of(features_to_remove)) %>%
  step_impute_median(all_predictors()) %>%
  step_YeoJohnson(all_predictors()) %>%
  step_normalize(all_predictors()) %>%
  step_downsample(target, seed = 123)

EDA_data <- recipe %>%
  prep() %>%
  juice()

EDA_data %>% colnames()

rf_model <- ranger(target ~ .,
  data = EDA_data,
  num.trees = 2000,
  importance = "impurity_corrected",
  min.node.size = 30,
  seed = 123
)

vip(rf_model, num_features = 30)

importance <- importance(rf_model)
importance[importance > 1]

try_vector <- as.numeric(importance) - 0.01
try_vector

results <- list()

for (n in try_vector) {
  keep_names <- names(importance[importance > n]) %>% c("target")

  rf_model_2 <- ranger(target ~ .,
    data = EDA_data %>%
      select(all_of(keep_names)),
    num.trees = 2000,
    min.node.size = 30,
    seed = 123
  )

  results[[paste(n)]] <- rf_model_2$prediction.error
}

results %>%
  as_tibble() %>%
  gather() %>%
  arrange(value) %>%
  slice_min(order_by = value, n = 30) %>%
  print(n = 50)

best_cut <- results %>%
  as_tibble() %>%
  gather() %>%
  arrange(value) %>%
  slice_min(order_by = value, n = 1) %>%
  pull(key)

selected_rf_features <- importance[importance > best_cut] %>% names()
selected_rf_features

rf_train_features <- gsub("na_ind_", "", selected_rf_features) %>%
  c("target")
rf_train_features

recipe_d1 <- train %>%
  select(all_of(rf_train_features)) %>%
  recipe(target ~ .) %>%
  step_mutate(target = as.factor(target)) %>%
  step_indicate_na(all_predictors())

rf_features <- recipe_d1 %>%
  prep() %>%
  juice() %>%
  dplyr::select(-target) %>%
  colnames()

rf_features_to_remove <- rf_features[!rf_features %in% selected_rf_features]
rf_features_to_remove
```

## Find important interactions 

Using lasso regression 

```{r}
recipe_lasso <- train %>%
  select(all_of(train_features)) %>%
  recipe(target ~ .) %>%
  step_mutate(target = as.factor(target)) %>%
  step_indicate_na(all_predictors()) %>%
  step_rm(all_of(features_to_remove)) %>%
  step_impute_median(all_predictors()) %>%
  step_interact(terms = ~ all_predictors():all_predictors(), sep = ":") %>%
  step_nzv(all_predictors()) %>%
  step_YeoJohnson(all_predictors()) %>%
  step_normalize(all_predictors())

lasso_spec <- logistic_reg(
  mode = "classification",
  engine = "glmnet",
  penalty = tune(),
  mixture = 1
)
lasso_spec

lasso_wf <- workflow(recipe_lasso, spec = lasso_spec)
lasso_wf

grid_lasso <- grid_regular(parameters(lasso_wf), levels = 20)
grid_lasso

lasso_results <- tune_grid(lasso_wf,
  resamples = train_folds,
  grid = grid_lasso
)

lasso_results
show_best(lasso_results)

penalty <- select_best(lasso_results) %>% pull(penalty)
penalty

lasso_wf <- finalize_workflow(x = lasso_wf, select_best(lasso_results))
lasso_wf

lasso_model <- fit(lasso_wf, data = train)

lasso_model %>%
  extract_fit_parsnip() %>%
  tidy() %>%
  filter(
    estimate != 0,
    term != "(Intercept)"
  ) %>%
  mutate(estimate = abs(estimate)) %>%
  arrange(desc(abs(estimate))) %>%
  ggplot(aes(x = estimate, y = reorder(term, estimate))) +
  geom_col() +
  labs(title = "Lasso Feature Importance Plot", y = "")

lasso_model %>%
  extract_fit_parsnip() %>%
  tidy() %>%
  filter(
    abs(estimate) > 0.04,
    term != "(Intercept)"
  ) %>%
  arrange(desc(abs(estimate))) %>%
  print(n = 100)

selected_lasso_features <- lasso_model %>%
  tidy() %>%
  filter(
    abs(estimate) > 0.05,
    term != "(Intercept)"
  ) %>%
  arrange(order_by = desc(abs(estimate))) %>%
  pull(term)

selected_lasso_features

interactions_terms <- grep(":", selected_lasso_features, value = T)
interactions_terms

left <- gsub("(\\w+):\\w+", "\\1", interactions_terms)
left

right <- gsub("\\w+:(\\w+)", "\\1", interactions_terms)
right

interactions_formula <- interactions_terms %>%
  paste(collapse = " + ")
interactions_formula <- paste("~", interactions_formula) %>% rlang::parse_expr()
interactions_formula

others <- selected_lasso_features[-grep(":", selected_lasso_features)]
others

all_lasso_features <- c(left, right, others) %>% unique()
all_lasso_features

lasso_train_features <- gsub("na_ind_", "", all_lasso_features) %>%
  c("target") %>%
  unique()
lasso_train_features

recipe_d2 <- train %>%
  select(all_of(lasso_train_features)) %>%
  recipe(target ~ .) %>%
  step_mutate(target = as.factor(target)) %>%
  step_indicate_na(all_predictors()) %>%
  step_interact(terms = interactions_formula, sep = ":")

lasso_features <- recipe_d2 %>%
  prep() %>%
  juice() %>%
  select(-target) %>%
  colnames()

lasso_features

no_int_lasso <- lasso_features[-grep(":", lasso_features)]

# check if all our interaction terms are indeed in our Juiced data
interactions_terms %>%
  as_tibble() %>%
  bind_cols(grep(":", lasso_features, value = T) %>%
    as_tibble())

lasso_features_to_remove <- no_int_lasso[!no_int_lasso %in% selected_lasso_features]
lasso_features_to_remove
```

Combine random with lasso features 

```{r}
rf_lasso_train <- c(rf_train_features, lasso_train_features) %>% unique()
rf_lasso_train

rf_lasso_selected <- c(selected_rf_features, selected_lasso_features) %>% unique()
rf_lasso_selected

interactions_formula

recipe_d3 <- train %>%
  select(all_of(rf_lasso_train)) %>%
  recipe(target ~ .) %>%
  step_mutate(target = as.factor(target)) %>%
  step_indicate_na(all_predictors()) %>%
  step_interact(terms = interactions_formula, sep = ":")

rf_lasso_features <- recipe_d3 %>%
  prep() %>%
  juice() %>%
  select(-target) %>%
  colnames()
rf_lasso_features

no_int_rf_lasso <- rf_lasso_features[-grep(":", rf_lasso_features)]
no_int_rf_lasso

rf_lasso_remove <- no_int_rf_lasso[!no_int_rf_lasso %in% rf_lasso_selected]
rf_lasso_remove
```

Step-wise feature selection 

```{r}
recipe_step_select <- train

base_mod <- glm(target ~ 1, data = EDA_data, family = binomial())
int_mod <- glm(target ~ .^2, data = EDA_data, family = binomial())

results_stepAIC <- list()

k_values <- seq(2, 4, 0.1)
k_values

# use the for loop to figure out the best value we should use for  stepAIC() (k) argument

for (n in k_values) {
  step_mod <- MASS::stepAIC(
    object = base_mod,
    scope = list(lower = base_mod, upper = int_mod),
    direction = "forward",
    k = n,
    trace = 1
  )
  results_stepAIC[[paste(n)]] <- step_mod$aic
}

results_stepAIC %>%
  unlist() %>%
  as_tibble(rownames = "K") %>%
  print(n = 30)

# choose K=3 because there is no significant gains for K values greater than 3 

step_mod <- MASS::stepAIC(
  object = base_mod,
  scope = list(lower = base_mod, upper = int_mod),
  direction = "forward",
  k = 3,
  trace = 1
)

step_selected_features <- step_mod$coefficients[-1] %>% names()
step_selected_features

step_selected_ints <- grep(":", step_selected_features, value = T)
step_selected_ints

step_left <- gsub("(\\w+):\\w+", "\\1", step_selected_ints)
step_left

step_right <- gsub("\\w+:(\\w+)", "\\1", step_selected_ints)
step_right

step_others <- step_selected_features[-grep(":", step_selected_features)]
step_others

step_train_features <- c(step_others, step_left, step_right, "target") %>% unique()
step_train_features <- gsub("na_ind_", "", step_train_features) %>% unique()
step_train_features

step_int_formula <- paste("~", paste(step_selected_ints, collapse = " + ")) %>%
  rlang::parse_expr()
step_int_formula

recipe_d4 <- train %>%
  select(all_of(step_train_features)) %>%
  recipe(target ~ .) %>%
  step_mutate(target = as.factor(target)) %>%
  step_indicate_na(all_predictors()) %>%
  step_interact(terms = step_int_formula, sep = ":")

step_features <- recipe_d4 %>%
  prep() %>%
  juice() %>%
  select(-target) %>%
  colnames()
step_features

# check if our interactions are indeed in our Juiced data
grep(":", step_features, value = T) %>%
  as_tibble() %>%
  bind_cols(step_selected_ints %>% as_tibble())

step_no_int <- step_features[-grep(":", step_features)]
step_no_int

step_features_to_remove <- step_no_int[!step_no_int %in% step_selected_features]
step_features_to_remove
```

## Compare selected feature sets 

use logistic regression to compare 

```{r}
log_spec <- logistic_reg(engine = "glm", mode = "classification")

recipe_rf <- train %>%
  select(all_of(rf_train_features)) %>%
  recipe(target ~ .) %>%
  step_mutate(target = as.factor(target)) %>%
  step_indicate_na(all_predictors()) %>%
  step_rm(all_of(rf_features_to_remove)) %>%
  step_YeoJohnson(all_predictors()) %>%
  step_downsample(target, seed = 123)

# check if rf selected features are indeed in our data
df_rf <- recipe_rf %>% prep() %>% juice()
selected_rf_features %in% colnames(df_rf)

recipe_lasso <- train %>%
  select(all_of(lasso_train_features)) %>%
  recipe(target ~ .) %>%
  step_mutate(target = as.factor(target)) %>%
  step_indicate_na(all_predictors()) %>%
  step_interact(terms = interactions_formula, sep = ":") %>%
  step_rm(all_of(lasso_features_to_remove)) %>%
  step_YeoJohnson(all_predictors()) %>%
  step_normalize(all_predictors()) %>%
  step_downsample(target, seed = 123)

# check if lasso features and interactions are in our data 
df_lasso <- recipe_lasso %>% prep() %>% juice()  
selected_lasso_features[-grep(":", selected_lasso_features)] %in% colnames(df_lasso)

selected_lasso_features[grep(":",selected_lasso_features)] %>% as_tibble()%>%
  bind_cols(interactions_terms %>% as_tibble())

recipe_rf_lasso <- train %>%
  select(all_of(rf_lasso_train)) %>%
  recipe(target ~ .) %>%
  step_mutate(target = as.factor(target)) %>%
  step_indicate_na(all_predictors()) %>%
  step_interact(terms = interactions_formula, sep = ":") %>%
  step_rm(all_of(rf_lasso_remove)) %>%
  step_YeoJohnson(all_predictors()) %>%
  step_normalize(all_predictors()) %>%
  step_downsample(target, seed = 123)

# check if rf_lasso selected features and interactions are indeed in our data   
df_rf_lasso <- recipe_rf_lasso %>% prep() %>% juice()
rf_lasso_selected[-grep(":",rf_lasso_selected)] %in% colnames(df_rf_lasso)

grep(":",colnames(df_rf_lasso),value = T) %>% as_tibble() %>%
  bind_cols(interactions_terms %>% as_tibble())

recipe_step <- train %>%
  select(all_of(step_train_features)) %>%
  recipe(target ~ .) %>%
  step_mutate(target = as.factor(target)) %>%
  step_indicate_na(all_predictors()) %>%
  step_interact(terms = step_int_formula, sep = ":") %>%
  step_rm(all_of(step_features_to_remove)) %>%
  step_YeoJohnson(all_predictors()) %>%
  step_normalize(all_predictors()) %>%
  step_downsample(target, seed = 123)

# check if our stepAIC selected features and interactions are indeed in our data 
df_step_colnames <- recipe_step %>% prep() %>% juice() %>% select(-target) %>% colnames()
df_step_colnames[-grep(":",df_step_colnames)] %in% step_selected_features

grep(":",step_features,value=T) %>% as_tibble() %>%
  bind_cols(step_selected_ints %>% as_tibble())


# Compare predictive power of each set 8using logistic regression .  

wf_set <- workflow_set(preproc = list(recipe_rf=recipe_rf,
                                      recipe_lasso=recipe_lasso,
                                      recipe_rf_lasso=recipe_rf_lasso,
                                      recipe_step=recipe_step),
                       models = list(log_model=log_spec),
                       cross = T)

wf_results <- workflow_map(wf_set,
                           fn = "fit_resamples",
                           resamples = train_folds,
                           seed = 123)

wf_results %>% collect_metrics() %>% filter(.metric=="roc_auc") %>%
  select(wflow_id , .metric , mean , std_err)
```

using random forest 

-  compare predictive power of each set using random forests

```{r}
# rf_spec <- rand_forest(mode = "classification",engine = "ranger",mtry = tune(),trees = tune(),min_n = tune())
# 
# wf_set <- workflow_set(preproc = list(recipe_lasso=recipe_lasso,
#                                       recipe_rf_lasso=recipe_rf_lasso,
#                                       recipe_step=recipe_step,
#                                       recipe_rf=recipe_rf),
#                        models = list(rf_model = rf_spec))
# 
# 
# wf_rf_results <- workflow_map(wf_set,
#                            resamples = train_folds,
#                            seed = 123,
#                            grid=20,
#                            control = control_grid(save_workflow = T))
# 
# wf_rf_results
# 
# wf_rf_results %>% autoplot()
# wf_rf_results %>% 
#   rank_results(select_best = T) %>%
#   filter(.metric == "roc_auc")
# 
# final_recipe <- recipe_rf_lasso
```

-  The above code takes too long to run , best recipe is recipe_rf_lasso


## Save the important features in our best recipe  

-  These are the features we will focus on going forward . For building our models . 

```{r}
rf_lasso_selected
rf_lasso_train
rf_lasso_remove
interactions_terms
interactions_formula

write.csv(rf_lasso_selected , "selected_features_eda.csv")
write.csv(rf_lasso_train , "train_features_eda.csv")
write.csv(rf_lasso_remove , "features_to_remove_eda.csv")
write.csv(interactions_terms , "interaction_terms_eda.csv")
saveRDS(interactions_formula , "interaction_formula_eda.rds")
```
